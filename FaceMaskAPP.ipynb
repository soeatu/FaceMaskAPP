{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceMaskAPP.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ee2mUnGG9M-i0qme35Cwk0Hk8vyG6ihd","authorship_tag":"ABX9TyPIAeWblpEjR79v3CTweXT6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_IEMSkdH4nW","executionInfo":{"status":"ok","timestamp":1633097171027,"user_tz":-540,"elapsed":4249,"user":{"displayName":"S A","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjN5Rn2L2i1TljR-lhFjxK8CsyP9Ora2TgDrx6=s64","userId":"10331105106267921281"}},"outputId":"f5b17aed-6fe0-4dc9-dd7d-ecec6b5b32f2"},"source":["pip install dlib"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (19.18.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DNQ_lC7LMRA","executionInfo":{"status":"ok","timestamp":1633097221009,"user_tz":-540,"elapsed":3333,"user":{"displayName":"S A","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjN5Rn2L2i1TljR-lhFjxK8CsyP9Ora2TgDrx6=s64","userId":"10331105106267921281"}},"outputId":"f626b7d4-6960-4df0-d50a-6d59f626ea47"},"source":["pip install opencv-python"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"]}]},{"cell_type":"code","metadata":{"id":"iaZVtHMPLdzH"},"source":["#@title 画像から顔切り取り\n","import cv2, dlib, sys, glob, pprint\n","\n","# 入力ディレクトリの指定\n","indir = \"#########\"\n","# 出力ディレクトリの指定\n","outdir = \"########\"\n","# 暫定的な画像のID\n","fid = 1000\n","# 入力画像をリサイズするか？\n","flag_resize = False\n","\n","# dlibをはじめる\n","detector = dlib.get_frontal_face_detector()\n","\n","# 顔画像を取得して保存する\n","def get_face(fname):\n","    global fid\n","    img = cv2.imread(fname)\n","    # デジタルカメラなどの画像であれば\n","    # サイズが大きいのでリサイズ\n","    if flag_resize:\n","        img = cv2.resize(img, None, fx = 0.2, fy = 0.2)\n","    # 顔検出\n","    dets = detector(img, 1)\n","    for k, d in enumerate(dets):\n","        pprint.pprint(d)\n","        x1 = int(d.left())\n","        y1 = int(d.top())\n","        x2 = int(d.right())\n","        y2 = int(d.bottom())\n","        im = img[y1:y2, x1:x2]\n","        # 50x50にリサイズ\n","        try:\n","            im = cv2.resize(im, (50, 50))\n","        except:\n","            continue\n","        # 保存\n","        out = outdir + \"/\" + str(fid) + \".jpg\"\n","        cv2.imwrite(out, im)\n","        fid += 1\n","\n","# ファイルを列挙して繰り返し顔検出を行う\n","files = glob.glob(indir+\"/*\")\n","for f in files:\n","    print(f)\n","    get_face(f)\n","print(\"ok\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3nzQHIDMHMY"},"source":["#@title 学習モデル生成\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.optimizers import RMSprop\n","import matplotlib.pyplot as plt\n","import cv2, glob\n","import numpy as np\n","\n","# 画像形式の指定\n","in_shape = (50, 50, 3)\n","nb_classes = 2\n","\n","# CNNモデル構造を定義\n","model = Sequential()\n","model = Sequential()\n","model.add(Conv2D(32,\n","          kernel_size=(3, 3),\n","          activation='relu',\n","          input_shape=in_shape))\n","model.add(Conv2D(32, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(nb_classes, activation='softmax'))\n","\n","# モデルをコンパイル\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=RMSprop(),\n","    metrics=['accuracy'])\n","\n","# 画像データをNumpy形式に変換\n","x = []\n","y = []\n","def read_files(target_files, y_val):\n","    files = glob.glob(target_files)\n","    for fname in files:\n","        print(fname)\n","        # 画像を読み出し\n","        img = cv2.imread(fname)\n","        # 画像サイズを50x50に変換\n","        img = cv2.resize(img, (50, 50))\n","        print(img)\n","        x.append(img)\n","        y.append(np.array(y_val))\n","\n","# ディレクトリ内の画像を集める\n","read_files(\"#######\", [1,0])\n","read_files(\"#######\", [0,1])\n","x_train, y_train = (np.array(x), np.array(y))\n","# テスト用の画像をNumpy形式で得る\n","x, y = [[], []]\n","read_files(\"#######\", [1,0])\n","read_files(\"#######\", [0,1])\n","x_test, y_test = (np.array(x), np.array(y))\n","# データを学習\n","hist = model.fit(x_train, y_train,\n","    batch_size=100,\n","    epochs=100,\n","    validation_data=(x_test, y_test))\n","# データを評価\n","score = model.evaluate(x_test, y_test, verbose=1)\n","print(\"正解率=\", score[1], 'loss=', score[0])\n","# モデルを保存\n","model.save('mask_model.h5')\n","# 学習の様子を描画\n","plt.plot(hist.history['accuracy'])\n","plt.plot(hist.history['val_accuracy'])\n","plt.title('Accuracy')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79EN9Jluh57W"},"source":["#@title ライブマスク判定\n","import keras\n","import cv2, dlib, pprint, os\n","import numpy as np\n","from keras.models import load_model\n","\n","# 結果ラベル\n","res_labels = ['NO MASK!!', 'Msk OK']\n","save_dir = \"######\"\n","\n","# 保存した学習データを読む \n","model = load_model('mask_model.h5')\n","\n","# Dlibをはじめる \n","detector = dlib.get_frontal_face_detector()\n","\n","# Webカメラから入力を開始 \n","red = (0,0,255)\n","green = (0, 255, 0)\n","fid = 1\n","cap = cv2.VideoCapture(0)\n","while True:\n","    # カメラの画像を読み込む\n","    ok, frame = cap.read()\n","    if not ok: break\n","    # 画像を縮小表示す\n","    frame = cv2.resize(frame, (500,300))\n","    # 顔検出\n","    dets = detector(frame, 1)\n","    for k, d in enumerate(dets):\n","        pprint.pprint(d)\n","        x1 = int(d.left())\n","        y1 = int(d.top())\n","        x2 = int(d.right())\n","        y2 = int(d.bottom())\n","        # 顔部分を切り取る\n","        im = frame[y1:y2, x1:x2]\n","        im = cv2.resize(im, (50, 50))\n","        im = im.reshape(-1, 50, 50, 3)\n","        # 予測\n","        res = model.predict([im])[0]\n","        v = res.argmax()\n","        print(res_labels[v], res)\n","        # 枠を描画\n","        color = green if v == 1 else red\n","        border = 2 if v == 1 else 7\n","        cv2.rectangle(frame, \n","          (x1, y1), (x2, y2), color, \n","          thickness=border)\n","        # テキストを描画\n","        cv2.putText(frame,\n","            res_labels[v], (x1, y1-7),\n","            cv2.FONT_HERSHEY_SIMPLEX,\n","            0.9, color, thickness=2)\n","    if len(dets) > 0: # 結果を保存\n","        if os.path.exists(save_dir):\n","            jpgfile = save_dir + \"/\" + str(fid) + \".png\"\n","            cv2.imwrite(jpgfile, frame)\n","            fid += 1\n","    # ウィンドウに画像を出力\n","    cv2.imshow('Mask Live Check', frame)\n","    # ESCかEnterキーが押されたらループを抜ける\n","    k = cv2.waitKey(1) # 1msec確認\n","    if k == 27 or k == 13: break\n","\n","cap.release() # カメラを解放\n","cv2.destroyAllWindows() # ウィンドウを破棄\n"],"execution_count":null,"outputs":[]}]}